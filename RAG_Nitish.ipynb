{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kif3jtNsHh-ameMWMku6sdfle_a1NjDq",
      "authorship_tag": "ABX9TyOz0kPd7yeSKJXYeIwRmez6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "992e0d46643f44f091c345d47d3ca82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9d5219fba85446a90ac0588819b764f",
              "IPY_MODEL_68044a451d1a430e9c2dcf24ba520bef",
              "IPY_MODEL_9f9119958bb64a78b9c5420596f8cfdc"
            ],
            "layout": "IPY_MODEL_0af8119b5a6149afa3b363c6840a0801"
          }
        },
        "e9d5219fba85446a90ac0588819b764f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e3fa52b87f4d50bf49480d30339086",
            "placeholder": "​",
            "style": "IPY_MODEL_ac97092a15174b5b928a57e5fc60a4b7",
            "value": "Batches: 100%"
          }
        },
        "68044a451d1a430e9c2dcf24ba520bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4941ffedd33944a18867f87ed7761a12",
            "max": 223,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83795fd10db348a3bf5442c1b4b766b2",
            "value": 223
          }
        },
        "9f9119958bb64a78b9c5420596f8cfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b198bd42bf45c983327d577c4baa93",
            "placeholder": "​",
            "style": "IPY_MODEL_82afa2ec78104328bdc6a623941e2326",
            "value": " 223/223 [30:18&lt;00:00,  3.53s/it]"
          }
        },
        "0af8119b5a6149afa3b363c6840a0801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e3fa52b87f4d50bf49480d30339086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac97092a15174b5b928a57e5fc60a4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4941ffedd33944a18867f87ed7761a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83795fd10db348a3bf5442c1b4b766b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b198bd42bf45c983327d577c4baa93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82afa2ec78104328bdc6a623941e2326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitishnarayanan002/RAG_on_Myntra_dataset/blob/main/RAG_Nitish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an RAG for Mytnra Dataset that was taken from the Kaggle and how the bot will respond to the queries asked by the user**"
      ],
      "metadata": {
        "id": "GyFFmlHdwNic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "mBlGKMvZwcjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Install Libraries"
      ],
      "metadata": {
        "id": "rYVXhTCrworu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install pandas openpyxl langchain pydantic chromadb sentence-transformers transformers accelerate rank_bm25\n",
        "# Install a high-performance cross-encoder for re-ranking\n",
        "!pip install --upgrade cohere\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6z_jv2HwLn1",
        "outputId": "71ea4340-7fa6-44d4-b39f-942592b9ba83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.77)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.12/dist-packages (5.18.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.12/dist-packages (from cohere) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.11.9)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.22.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<1,>=0.15->cohere) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Mount Google Drive and API key"
      ],
      "metadata": {
        "id": "NTaCaut6w5xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata # <-- CORRECT IMPORT\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from getpass import getpass\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Get Perplexity API Key from Colab Secrets using `userdata`\n",
        "# NOTE: The secret name is case-sensitive and must match what you set in Colab Secrets.\n",
        "SECRET_NAME = 'PERPLEXITY_API_KEY'\n",
        "\n",
        "try:\n",
        "    # Use the correct method to retrieve the key\n",
        "    PPLX_API_KEY = userdata.get(SECRET_NAME)\n",
        "\n",
        "    if PPLX_API_KEY is None:\n",
        "        print(f\"Error: Secret '{SECRET_NAME}' not found. Please ensure it is saved correctly in Colab Secrets.\")\n",
        "        # Fallback for manual entry if the secret is not set\n",
        "        PPLX_API_KEY = getpass(f\"Enter your {SECRET_NAME} manually: \")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the secret: {e}\")\n",
        "    PPLX_API_KEY = getpass(f\"Enter your {SECRET_NAME} manually: \")\n",
        "\n",
        "# Check if key is available\n",
        "if PPLX_API_KEY:\n",
        "    print(f\"Perplexity API Key loaded successfully for RAG project.\")\n",
        "else:\n",
        "    # This should stop execution if the key is mandatory for the project\n",
        "    raise ValueError(\"FATAL ERROR: Perplexity API Key is required but could not be loaded or entered.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJZWYA7ixJvx",
        "outputId": "16e1fddc-27cd-41d0-cc6b-35a4c0ad9507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Perplexity API Key loaded successfully for RAG project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preparation and Document Creation"
      ],
      "metadata": {
        "id": "cx47aWVnyp3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to convert the tabular data into text documents suitable for RAG."
      ],
      "metadata": {
        "id": "Y2fJ7Rlby8_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Import numpy for isna checks\n",
        "\n",
        "# Define the path to your dataset\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Fashion Dataset v2.xlsx\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(DATASET_PATH)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {DATASET_PATH}. Please check your path.\")\n",
        "    raise # Stop execution if the file isn't found\n",
        "\n",
        "# --- COLUMN MAPPING AND CLEANING FIX ---\n",
        "# 1. Clean the column names by stripping whitespace (already done, but keep for robustness)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# 2. Map the required RAG columns to the actual dataset columns\n",
        "# We will use 'name', 'brand', and 'p_attributes' as the core descriptive fields.\n",
        "CRITICAL_COLUMNS = ['name', 'brand', 'p_attributes']\n",
        "\n",
        "# Check if all critical columns exist after cleaning\n",
        "if not all(col in df.columns for col in CRITICAL_COLUMNS):\n",
        "    # This should now never run if the column list above is correct\n",
        "    missing_cols = [col for col in CRITICAL_COLUMNS if col not in df.columns]\n",
        "    raise KeyError(f\"FATAL: Missing required columns: {missing_cols}.\")\n",
        "\n",
        "# Drop rows with any missing values that are critical for search\n",
        "df.dropna(subset=CRITICAL_COLUMNS, inplace=True)\n",
        "\n",
        "# Create a 'document' column by concatenating relevant product attributes\n",
        "def create_document_text(row):\n",
        "    \"\"\"Formats a single product entry into a comprehensive text document using actual column names.\"\"\"\n",
        "\n",
        "    # Use 'colour' for color and 'products' for category/type\n",
        "    color = row['colour'] if 'colour' in row and pd.notna(row.get('colour')) else 'N/A'\n",
        "    category = row['products'] if 'products' in row and pd.notna(row.get('products')) else 'General'\n",
        "    product_id = row['p_id'] if 'p_id' in row and pd.notna(row.get('p_id')) else 'N/A'\n",
        "\n",
        "    # Use 'description' if 'p_attributes' is missing, though we dropped NaN rows for 'p_attributes'\n",
        "    attributes = row['p_attributes'] if 'p_attributes' in row and pd.notna(row.get('p_attributes')) else row.get('description', 'N/A')\n",
        "\n",
        "    doc_text = (\n",
        "        f\"Product Name: {row['name']}\\n\"\n",
        "        f\"Brand: {row['brand']}\\n\"\n",
        "        f\"Category: {category}\\n\"\n",
        "        f\"Product ID: {product_id}\\n\"\n",
        "        f\"Color: {color}\\n\"\n",
        "        f\"Attributes/Features: {attributes}\\n\"\n",
        "        f\"Price: {row.get('price', 'N/A')}\\n\"\n",
        "        f\"Average Rating: {row.get('avg_rating', 'N/A')}\"\n",
        "    )\n",
        "    return doc_text\n",
        "\n",
        "df['document_content'] = df.apply(create_document_text, axis=1)\n",
        "\n",
        "# The list of documents to be processed by the embedding model\n",
        "documents = df['document_content'].tolist()\n",
        "\n",
        "print(f\"\\nLoaded and processed {len(documents)} documents for RAG system using columns: {CRITICAL_COLUMNS}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uOovQBsy5Ik",
        "outputId": "b8170283-3791-4c63-89bf-7baec1fcb024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded and processed 14214 documents for RAG system using columns: ['name', 'brand', 'p_attributes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. The Embedding Layer: Experimentation"
      ],
      "metadata": {
        "id": "71S4sx5908ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This layer is about converting your text documents into numerical vectors."
      ],
      "metadata": {
        "id": "6HxsRJBW0_xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Embeding the model\n"
      ],
      "metadata": {
        "id": "NrmewJo91XJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV1iFWvq2vGN",
        "outputId": "f43faf85-214e-4eda-d370-6d9dc3a4c5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFw7WZTT3TVg",
        "outputId": "e55e8e4a-678d-46db-cd4c-9eab25a308ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# --- CHOOSE YOUR MODEL FOR IMPLEMENTATION ---\n",
        "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "print(f\"Loading Sentence Transformer: {EMBEDDING_MODEL_NAME}\")\n",
        "\n",
        "# Use GPU if available for faster embedding generation\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=device)\n",
        "\n",
        "# --- 1. Generate Embeddings for All Documents ---\n",
        "print(f\"Generating embeddings for {len(documents)} chunks...\")\n",
        "\n",
        "# Efficient encoding with batching, GPU, and progress bar\n",
        "embeddings = model.encode(\n",
        "    documents,\n",
        "    convert_to_tensor=True,\n",
        "    device=device,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=64  # Adjust if you face memory errors\n",
        ").cpu().numpy()\n",
        "\n",
        "print(f\" Embeddings generated successfully: shape = {embeddings.shape}\")\n",
        "\n",
        "# --- 2. Prepare Metadata and IDs ---\n",
        "# Ensure 'p_id' exists and has no NaNs\n",
        "if 'p_id' not in df.columns:\n",
        "    raise KeyError(\"FATAL: 'p_id' column missing from dataframe.\")\n",
        "\n",
        "df = df[df['p_id'].notna()].reset_index(drop=True)\n",
        "\n",
        "ids = [str(pid) for pid in df['p_id']]\n",
        "metadatas = [{\"source\": \"Myntra Dataset\", \"p_id\": str(pid)} for pid in df['p_id']]\n",
        "\n",
        "# Sanity check: lengths must match\n",
        "assert len(ids) == len(documents) == len(embeddings) == len(metadatas), \\\n",
        "    f\"Length mismatch: ids={len(ids)}, docs={len(documents)}, emb={len(embeddings)}, meta={len(metadatas)}\"\n",
        "\n",
        "# --- 3. Initialize and Populate ChromaDB ---\n",
        "PERSIST_DIRECTORY = \"./chroma_db_direct\"\n",
        "COLLECTION_NAME = \"myntra_products\"\n",
        "\n",
        "# Use in-memory client first for speed; switch to PersistentClient once stable\n",
        "# chroma_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY)\n",
        "chroma_client = chromadb.Client()  # Faster for Colab testing\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        ")\n",
        "\n",
        "# --- 4. Add Data to the Collection in Batches ---\n",
        "batch_size = 200\n",
        "print(\"Adding data to ChromaDB in batches...\")\n",
        "\n",
        "for i in range(0, len(ids), batch_size):\n",
        "    print(f\"→ Adding batch {i // batch_size + 1} / {len(ids) // batch_size + 1}\")\n",
        "    collection.add(\n",
        "        embeddings=embeddings[i:i + batch_size],\n",
        "        documents=documents[i:i + batch_size],\n",
        "        metadatas=metadatas[i:i + batch_size],\n",
        "        ids=ids[i:i + batch_size],\n",
        "    )\n",
        "\n",
        "print(f\"ChromaDB collection '{COLLECTION_NAME}' created successfully!\")\n",
        "\n",
        "# --- 5. Helper Function for Direct Search ---\n",
        "def direct_chroma_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Performs vector search directly against the ChromaDB collection.\"\"\"\n",
        "    # Embed the query using the same model\n",
        "    query_embedding = model.encode([query], convert_to_tensor=False, show_progress_bar=False)\n",
        "\n",
        "    # Perform vector similarity search\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding,\n",
        "        n_results=k,\n",
        "        include=['documents', 'distances', 'metadatas']\n",
        "    )\n",
        "\n",
        "    # Format output for readability\n",
        "    formatted_results = []\n",
        "    if results.get('documents') and results.get('distances'):\n",
        "        for i in range(len(results['documents'][0])):\n",
        "            formatted_results.append({\n",
        "                \"content\": results['documents'][0][i],\n",
        "                \"score\": results['distances'][0][i],\n",
        "                \"metadata\": results['metadatas'][0][i],\n",
        "            })\n",
        "\n",
        "    return formatted_results\n",
        "\n",
        "print(\" direct_chroma_search() ready for use!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "992e0d46643f44f091c345d47d3ca82a",
            "e9d5219fba85446a90ac0588819b764f",
            "68044a451d1a430e9c2dcf24ba520bef",
            "9f9119958bb64a78b9c5420596f8cfdc",
            "0af8119b5a6149afa3b363c6840a0801",
            "e0e3fa52b87f4d50bf49480d30339086",
            "ac97092a15174b5b928a57e5fc60a4b7",
            "4941ffedd33944a18867f87ed7761a12",
            "83795fd10db348a3bf5442c1b4b766b2",
            "34b198bd42bf45c983327d577c4baa93",
            "82afa2ec78104328bdc6a623941e2326"
          ]
        },
        "id": "AR6LoEXd1aXW",
        "outputId": "46331c4d-3a90-4228-a27f-fd8b9093a330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Sentence Transformer: all-MiniLM-L6-v2\n",
            "Using device: cpu\n",
            "Generating embeddings for 14214 chunks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/223 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "992e0d46643f44f091c345d47d3ca82a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Embeddings generated successfully: shape = (14214, 384)\n",
            "Adding data to ChromaDB in batches...\n",
            "→ Adding batch 1 / 72\n",
            "→ Adding batch 2 / 72\n",
            "→ Adding batch 3 / 72\n",
            "→ Adding batch 4 / 72\n",
            "→ Adding batch 5 / 72\n",
            "→ Adding batch 6 / 72\n",
            "→ Adding batch 7 / 72\n",
            "→ Adding batch 8 / 72\n",
            "→ Adding batch 9 / 72\n",
            "→ Adding batch 10 / 72\n",
            "→ Adding batch 11 / 72\n",
            "→ Adding batch 12 / 72\n",
            "→ Adding batch 13 / 72\n",
            "→ Adding batch 14 / 72\n",
            "→ Adding batch 15 / 72\n",
            "→ Adding batch 16 / 72\n",
            "→ Adding batch 17 / 72\n",
            "→ Adding batch 18 / 72\n",
            "→ Adding batch 19 / 72\n",
            "→ Adding batch 20 / 72\n",
            "→ Adding batch 21 / 72\n",
            "→ Adding batch 22 / 72\n",
            "→ Adding batch 23 / 72\n",
            "→ Adding batch 24 / 72\n",
            "→ Adding batch 25 / 72\n",
            "→ Adding batch 26 / 72\n",
            "→ Adding batch 27 / 72\n",
            "→ Adding batch 28 / 72\n",
            "→ Adding batch 29 / 72\n",
            "→ Adding batch 30 / 72\n",
            "→ Adding batch 31 / 72\n",
            "→ Adding batch 32 / 72\n",
            "→ Adding batch 33 / 72\n",
            "→ Adding batch 34 / 72\n",
            "→ Adding batch 35 / 72\n",
            "→ Adding batch 36 / 72\n",
            "→ Adding batch 37 / 72\n",
            "→ Adding batch 38 / 72\n",
            "→ Adding batch 39 / 72\n",
            "→ Adding batch 40 / 72\n",
            "→ Adding batch 41 / 72\n",
            "→ Adding batch 42 / 72\n",
            "→ Adding batch 43 / 72\n",
            "→ Adding batch 44 / 72\n",
            "→ Adding batch 45 / 72\n",
            "→ Adding batch 46 / 72\n",
            "→ Adding batch 47 / 72\n",
            "→ Adding batch 48 / 72\n",
            "→ Adding batch 49 / 72\n",
            "→ Adding batch 50 / 72\n",
            "→ Adding batch 51 / 72\n",
            "→ Adding batch 52 / 72\n",
            "→ Adding batch 53 / 72\n",
            "→ Adding batch 54 / 72\n",
            "→ Adding batch 55 / 72\n",
            "→ Adding batch 56 / 72\n",
            "→ Adding batch 57 / 72\n",
            "→ Adding batch 58 / 72\n",
            "→ Adding batch 59 / 72\n",
            "→ Adding batch 60 / 72\n",
            "→ Adding batch 61 / 72\n",
            "→ Adding batch 62 / 72\n",
            "→ Adding batch 63 / 72\n",
            "→ Adding batch 64 / 72\n",
            "→ Adding batch 65 / 72\n",
            "→ Adding batch 66 / 72\n",
            "→ Adding batch 67 / 72\n",
            "→ Adding batch 68 / 72\n",
            "→ Adding batch 69 / 72\n",
            "→ Adding batch 70 / 72\n",
            "→ Adding batch 71 / 72\n",
            "→ Adding batch 72 / 72\n",
            "ChromaDB collection 'myntra_products' created successfully!\n",
            " direct_chroma_search() ready for use!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 4. The Search Layer: Confirmation & Query Refinement"
      ],
      "metadata": {
        "id": "Fxr1Mai0U90x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This layer handles retrieving relevant chunks and refining the results."
      ],
      "metadata": {
        "id": "hjvuROmfVUCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Implementing Caching for Search"
      ],
      "metadata": {
        "id": "5T_naMFrVcEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any\n",
        "\n",
        "# Simple in-memory cache\n",
        "search_cache = {}\n",
        "\n",
        "def get_cached_or_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Checks cache first; if not found, performs vector search on ChromaDB.\n",
        "    Uses direct_chroma_search() from Step 4.\n",
        "    \"\"\"\n",
        "    cache_key = (query.lower().strip(), k)\n",
        "\n",
        "    if cache_key in search_cache:\n",
        "        print(f\" Cache Hit for query: '{query}'\")\n",
        "        return search_cache[cache_key]\n",
        "\n",
        "    print(f\" Cache Miss for query: '{query}'. Performing vector search...\")\n",
        "    results = direct_chroma_search(query, k=k)\n",
        "\n",
        "    # Cache the results\n",
        "    search_cache[cache_key] = results\n",
        "    return results\n",
        "\n",
        "# --- Example Queries for Testing ---\n",
        "queries = {\n",
        "    \"Query 1\" : \"Do you have ethnic wear?\",\n",
        "    \"Query 2\": \"I'm looking for Kurtas and Trousers\",\n",
        "   \"Query 3\": \"Describe the fabric and features of W Women.\"\n",
        "}\n",
        "\n",
        "for qid, qtext in queries.items():\n",
        "    print(f\"\\n {qid}: {qtext}\")\n",
        "    res = get_cached_or_search(qtext, k=5)\n",
        "    for idx, r in enumerate(res, 1):\n",
        "        print(f\"\\nResult {idx}:\")\n",
        "        print(f\"→ Score: {r['score']:.4f}\")\n",
        "        print(f\"→ Product ID: {r['metadata'].get('p_id', 'N/A')}\")\n",
        "        print(f\"→ Content: {r['content'][:250]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcwzLgp5WOQr",
        "outputId": "b71335db-ec8c-4204-b204-d8410990a08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Query 1: Do you have ethnic wear?\n",
            " Cache Miss for query: 'Do you have ethnic wear?'. Performing vector search...\n",
            "\n",
            "Result 1:\n",
            "→ Score: 0.9415\n",
            "→ Product ID: 15723640\n",
            "→ Content: Product Name: Ethnicity Gold-Toned Ethnic Embellished Regular Top\n",
            "Brand: Ethnicity\n",
            "Category: Top\n",
            "Product ID: 15723640\n",
            "Color: Gold\n",
            "Attributes/Features: {'Body Shape ID': '443,333,424', 'Body or Garment Size': 'Garment Measurements in', 'Center Front O...\n",
            "\n",
            "Result 2:\n",
            "→ Score: 0.9517\n",
            "→ Product ID: 17577456\n",
            "→ Content: Product Name: Indo Era Women Classic Off-White Ethnic Motifs Nuovo Sleeves Top\n",
            "Brand: Indo Era\n",
            "Category: Top\n",
            "Product ID: 17577456\n",
            "Color: Off White\n",
            "Attributes/Features: {'Body Shape ID': '443,333,424', 'Body or Garment Size': 'Garment Measurements in'...\n",
            "\n",
            "Result 3:\n",
            "→ Score: 0.9523\n",
            "→ Product ID: 16588088\n",
            "→ Content: Product Name: Ancestry Pink & Black Ethnic Motifs Print Bishop Sleeves Modal Regular Top\n",
            "Brand: Ancestry\n",
            "Category: Top\n",
            "Product ID: 16588088\n",
            "Color: Pink\n",
            "Attributes/Features: {'Body Shape ID': '333,324,424', 'Body or Garment Size': 'Garment Measurement...\n",
            "\n",
            "Result 4:\n",
            "→ Score: 0.9617\n",
            "→ Product ID: 17577466\n",
            "→ Content: Product Name: Indo Era Women Bright Orange Ethnic Fusion Top\n",
            "Brand: Indo Era\n",
            "Category: Top\n",
            "Product ID: 17577466\n",
            "Color: Orange\n",
            "Attributes/Features: {'Body Shape ID': '443,333,424', 'Body or Garment Size': 'Garment Measurements in', 'Care for me': 'NA'...\n",
            "\n",
            "Result 5:\n",
            "→ Score: 0.9630\n",
            "→ Product ID: 17850262\n",
            "→ Content: Product Name: TAG 7 Women White Ethnic Motifs Embellished Flared Palazzos\n",
            "Brand: TAG 7\n",
            "Category: Palazzos\n",
            "Product ID: 17850262\n",
            "Color: White\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Care for me': 'Follow th...\n",
            "\n",
            " Query 2: I'm looking for Kurtas and Trousers\n",
            " Cache Miss for query: 'I'm looking for Kurtas and Trousers'. Performing vector search...\n",
            "\n",
            "Result 1:\n",
            "→ Score: 0.7287\n",
            "→ Product ID: 15886988\n",
            "→ Content: Product Name: HERE&NOW Women Blue Solid Kurta with Trousers\n",
            "Brand: HERE&NOW\n",
            "Category: Kurta, Trousers\n",
            "Product ID: 15886988\n",
            "Color: Blue\n",
            "Attributes/Features: {'Add-Ons': 'NA', 'Body Shape ID': '333,424', 'Body or Garment Size': 'Garment Measurements in...\n",
            "\n",
            "Result 2:\n",
            "→ Score: 0.7312\n",
            "→ Product ID: 19016206\n",
            "→ Content: Product Name: Cot'N Soft Women Black & White Striped Dobby Kurta\n",
            "Brand: Cot'N Soft\n",
            "Category: Kurta\n",
            "Product ID: 19016206\n",
            "Color: Black\n",
            "Attributes/Features: {'About the Brand': \"supporting traditional 2000 years old craft and helping artisians in rural ...\n",
            "\n",
            "Result 3:\n",
            "→ Score: 0.7676\n",
            "→ Product ID: 16926908\n",
            "→ Content: Product Name: FASHION DEPTH Women Black Ethnic Motifs Embroidered Kurta\n",
            "Brand: FASHION DEPTH\n",
            "Category: Kurta\n",
            "Product ID: 16926908\n",
            "Color: Black\n",
            "Attributes/Features: {'About the Brand': 'fashion depth is a lifestyle brand which provides you unique desg...\n",
            "\n",
            "Result 4:\n",
            "→ Score: 0.7730\n",
            "→ Product ID: 2339842\n",
            "→ Content: Product Name: Jaipur Kurti Women Cream-Coloured Casual Trousers\n",
            "Brand: Jaipur Kurti\n",
            "Category: Trousers\n",
            "Product ID: 2339842\n",
            "Color: Cream\n",
            "Attributes/Features: {'Add-Ons': 'NA', 'Body Shape ID': '443,333,424', 'Body or Garment Size': 'To-Fit Denotes Bod...\n",
            "\n",
            "Result 5:\n",
            "→ Score: 0.7734\n",
            "→ Product ID: 13895534\n",
            "→ Content: Product Name: Inddus Women Purple Solid Kurta with Trousers & Dupatta\n",
            "Brand: Inddus\n",
            "Category: Kurta, Trousers, Dupatta\n",
            "Product ID: 13895534\n",
            "Color: Purple\n",
            "Attributes/Features: {'Add-Ons': 'NA', 'Body Shape ID': '333,424', 'Body or Garment Size': 'To-F...\n",
            "\n",
            " Query 3: Describe the fabric and features of W Women.\n",
            " Cache Miss for query: 'Describe the fabric and features of W Women.'. Performing vector search...\n",
            "\n",
            "Result 1:\n",
            "→ Score: 0.8525\n",
            "→ Product ID: 13646388\n",
            "→ Content: Product Name: W Women Off-White & Black Printed Flared Maxi Skirt\n",
            "Brand: W\n",
            "Category: Maxi Skirt\n",
            "Product ID: 13646388\n",
            "Color: Off White\n",
            "Attributes/Features: {'Add-Ons': 'NA', 'Body Shape ID': '324,333,424', 'Body or Garment Size': 'To-Fit Denotes Body ...\n",
            "\n",
            "Result 2:\n",
            "→ Score: 0.8588\n",
            "→ Product ID: 2184770\n",
            "→ Content: Product Name: W Women Navy Wide Leg Solid Palazzos\n",
            "Brand: W\n",
            "Category: Palazzos\n",
            "Product ID: 2184770\n",
            "Color: Navy Blue\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Closure': 'Zip', 'Fabric': 'Acrylic', 'Fabric 2'...\n",
            "\n",
            "Result 3:\n",
            "→ Score: 0.8597\n",
            "→ Product ID: 9791943\n",
            "→ Content: Product Name: Clora Creation Women Black Straight Embroidered Palazzos\n",
            "Brand: Clora Creation\n",
            "Category: Palazzos\n",
            "Product ID: 9791943\n",
            "Color: Black\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Closure': 'Slip-On'...\n",
            "\n",
            "Result 4:\n",
            "→ Score: 0.8600\n",
            "→ Product ID: 13084204\n",
            "→ Content: Product Name: Miaz Lifestyle Women White Solid Straight Palazzos\n",
            "Brand: Miaz Lifestyle\n",
            "Category: Palazzos\n",
            "Product ID: 13084204\n",
            "Color: White\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Closure': 'Slip-On', 'Fa...\n",
            "\n",
            "Result 5:\n",
            "→ Score: 0.8608\n",
            "→ Product ID: 10428804\n",
            "→ Content: Product Name: Clora Creation Women White Embroidered Straight Palazzos\n",
            "Brand: Clora Creation\n",
            "Category: Palazzos\n",
            "Product ID: 10428804\n",
            "Color: White\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Closure': 'Drawstr...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Implementing Re-ranking"
      ],
      "metadata": {
        "id": "ajsysWpHZOVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a high-performance cross-encoder from HuggingFace to re-rank the initial top 10 retrieved chunks."
      ],
      "metadata": {
        "id": "r5HTq9eOZZRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "\n",
        "# --- Reranker Model (Cross-Encoder) ---\n",
        "RERANKER_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # Lightweight and effective\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(RERANKER_MODEL_NAME)\n",
        "reranker_model = AutoModelForSequenceClassification.from_pretrained(RERANKER_MODEL_NAME)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "reranker_model.to(device)\n",
        "\n",
        "# --- Re-ranking Function ---\n",
        "def rerank_documents(query: str, initial_results: List[Dict[str, Any]], top_n: int = 3) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Re-ranks retrieved documents using a cross-encoder (semantic re-ranking).\n",
        "    \"\"\"\n",
        "    if not initial_results:\n",
        "        print(\"No documents to rerank.\")\n",
        "        return []\n",
        "\n",
        "    # Form query-document pairs\n",
        "    pairs = [[query, doc['content']] for doc in initial_results]\n",
        "\n",
        "    # Tokenize and infer scores\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(\n",
        "            pairs,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "        scores = reranker_model(**inputs).logits.squeeze(-1).cpu().numpy()\n",
        "\n",
        "    # Attach re-rank scores\n",
        "    for i, doc in enumerate(initial_results):\n",
        "        doc['rerank_score'] = float(scores[i])\n",
        "\n",
        "    # Sort and return top_n\n",
        "    reranked_results = sorted(initial_results, key=lambda x: x['rerank_score'], reverse=True)\n",
        "    return reranked_results[:top_n]\n",
        "\n",
        "# --- Updated Caching Layer (works with direct_chroma_search) ---\n",
        "search_cache = {}\n",
        "\n",
        "def get_cached_or_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Checks cache first, otherwise performs ChromaDB vector search.\"\"\"\n",
        "    cache_key = (query, k)\n",
        "\n",
        "    if cache_key in search_cache:\n",
        "        print(f\"Cache Hit for query: '{query}'\")\n",
        "        return search_cache[cache_key]\n",
        "\n",
        "    print(f\"Cache Miss for query: '{query}'. Performing vector search...\")\n",
        "    results = direct_chroma_search(query, k=k)  # Uses your ChromaDB retrieval\n",
        "\n",
        "    # Save to cache\n",
        "    search_cache[cache_key] = results\n",
        "    return results\n",
        "\n",
        "# --- Run Test ---\n",
        "TEST_QUERY = \"What are some options of Libas?\"\n",
        "K_INITIAL_RETRIEVAL = 10  # Retrieve top 10 from Chroma\n",
        "TOP_N_RERANKED = 3        # Rerank top 3\n",
        "\n",
        "#  Initial retrieval\n",
        "initial_results = get_cached_or_search(TEST_QUERY, k=K_INITIAL_RETRIEVAL)\n",
        "\n",
        "# Reranking\n",
        "final_context = rerank_documents(TEST_QUERY, initial_results, top_n=TOP_N_RERANKED)\n",
        "\n",
        "print(\"\\n--- RERANKED TOP 3 CONTEXT CHUNKS ---\")\n",
        "for i, chunk in enumerate(final_context):\n",
        "    print(f\"\\nRANK {i+1} (Rerank Score: {chunk['rerank_score']:.4f}):\")\n",
        "    print(chunk['content'][:300], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8JRhhPgZdq2",
        "outputId": "b3a61982-39e1-4771-b186-7d029c092aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache Miss for query: 'What are some options of Libas?'. Performing vector search...\n",
            "\n",
            "--- RERANKED TOP 3 CONTEXT CHUNKS ---\n",
            "\n",
            "RANK 1 (Rerank Score: -1.1954):\n",
            "Product Name: Libas Women Stylish Black Embellished Tiered Skirt\n",
            "Brand: Libas\n",
            "Category: Skirt\n",
            "Product ID: 16872736\n",
            "Color: Black\n",
            "Attributes/Features: {'Add-Ons': 'NA', 'Body Shape ID': '443,324,333,424', 'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Character': 'NA', 'Closure': 'Dra ...\n",
            "\n",
            "RANK 2 (Rerank Score: -1.5515):\n",
            "Product Name: Libas Women Blue Floral Printed Ethnic Palazzos\n",
            "Brand: Libas\n",
            "Category: Palazzos\n",
            "Product ID: 17644444\n",
            "Color: Blue\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Care for me': 'NA', 'Closure': 'Slip-On', 'Fabric': 'Silk', 'Fabric 2': 'Blended', 'Fit ...\n",
            "\n",
            "RANK 3 (Rerank Score: -1.6717):\n",
            "Product Name: Libas Women Pink Floral Printed Ethnic Palazzos\n",
            "Brand: Libas\n",
            "Category: Palazzos\n",
            "Product ID: 17644516\n",
            "Color: Pink\n",
            "Attributes/Features: {'Body or Garment Size': 'To-Fit Denotes Body Measurements in', 'Care for me': 'NA', 'Closure': 'Slip-On', 'Fabric': 'Silk', 'Fabric 2': 'Blended', 'Fit ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generation Layer"
      ],
      "metadata": {
        "id": "WEFxZgDIaVY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This layer uses the retrieved context to generate the final, coherent answer."
      ],
      "metadata": {
        "id": "C6UqgEQraeyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1  Perplexity API Function"
      ],
      "metadata": {
        "id": "YD9tjVNmwE3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_with_pplx(query: str, context: List[Dict[str, Any]]) -> str:\n",
        "    \"\"\"\n",
        "    Calls the Perplexity API with the user query and retrieved context.\n",
        "    \"\"\"\n",
        "    if not context:\n",
        "        return \"I could not find any relevant information in the Myntra dataset to answer your query.\"\n",
        "\n",
        "    # 1. Structure the Context for the LLM\n",
        "    context_text = \"\\n---\\n\".join([doc['content'] for doc in context])\n",
        "\n",
        "    # 2. Design the Exhaustive Prompt Template\n",
        "    SYSTEM_PROMPT = (\n",
        "        \"You are an expert Myntra fashion product knowledge assistant. \"\n",
        "        \"Your task is to answer the user's question based ONLY on the provided context. \"\n",
        "        \"If the context does not contain the answer, state clearly that the information is unavailable in the provided product catalog. \"\n",
        "        \"Format the output clearly using a bulleted or numbered list of products and their key details (Name, Brand, ID, Color, and a summary of the Attributes). \"\n",
        "        \"Ensure the final answer is coherent and directly addresses the user's request.\"\n",
        "    )\n",
        "\n",
        "    # 3. Create the Full Prompt (Including Few-shot Example - Optional but recommended)\n",
        "    # Few-shot example structure:\n",
        "    # Example Query, Example Context, Example Answer (not implemented here for brevity, but recommended for report)\n",
        "\n",
        "    USER_MESSAGE = (\n",
        "        f\"Based on the Myntra Product Catalog data provided below, answer the following question:\\n\\n\"\n",
        "        f\"--- USER QUERY ---\\n{query}\\n\\n\"\n",
        "        f\"--- RELEVANT PRODUCT CATALOG DATA ---\\n{context_text}\\n\"\n",
        "        f\"--- END OF DATA ---\"\n",
        "    )\n",
        "\n",
        "    # 4. API Call Configuration\n",
        "    url = \"https://api.perplexity.ai/chat/completions\"\n",
        "\n",
        "    # --- Experimentation Block: Change the model here ---\n",
        "    # Experiment 1 (Online): \"sonar-medium-online\"\n",
        "    # Experiment 2 (Chat): \"sonar-small-chat\"\n",
        "    MODEL_NAME = \"sonar\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"authorization\": f\"Bearer {PPLX_API_KEY}\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        response_data = response.json()\n",
        "\n",
        "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
        "            return response_data['choices'][0]['message']['content']\n",
        "        else:\n",
        "            return \"Error: Perplexity API did not return a valid response.\"\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"An error occurred during the API call: {e}\""
      ],
      "metadata": {
        "id": "aoFsxZZmai_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2: Final Testing and Output"
      ],
      "metadata": {
        "id": "jvzjM9hvat_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "three queries to get the final generated answers."
      ],
      "metadata": {
        "id": "nvMm-9M_azee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of your 3 self-designed queries\n",
        "all_test_queries = [\n",
        "    \"Do you have ethnic wear?\",\n",
        "    \"I'm looking for Kurtas and Trousers\",\n",
        "    \"Describe the fabric and features of W Women.\"\n",
        "]\n",
        "\n",
        "for i, query in enumerate(all_test_queries):\n",
        "    print(f\"\\n\\n=======================================================\")\n",
        "    print(f\"TESTING QUERY {i+1}: {query}\")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    # 1. Search Layer (Retrieval)\n",
        "    initial_results = get_cached_or_search(query, k=10) # Using k=10 for initial search\n",
        "\n",
        "    # 2. Search Layer (Re-ranking)\n",
        "    # Get the final 3 best chunks to pass as context\n",
        "    final_context = rerank_documents(query, initial_results, top_n=3)\n",
        "\n",
        "    print(\"\\n[CONTEXT]:\")\n",
        "    for j, chunk in enumerate(final_context):\n",
        "        print(f\"  Chunk {j+1} (Rerank Score: {chunk['rerank_score']:.4f}): {chunk['content'][:50]}...\")\n",
        "\n",
        "    # 3. Generation Layer (LLM Call)\n",
        "    final_answer = generate_answer_with_pplx(query, final_context)\n",
        "\n",
        "    print(\"\\n[FINAL GENERATED ANSWER (Perplexity Sonar)]:\")\n",
        "    print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MmQEWuIapda",
        "outputId": "11f7f540-f53a-457e-bc8b-9dd956d64b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=======================================================\n",
            "TESTING QUERY 1: Do you have ethnic wear?\n",
            "=======================================================\n",
            "Cache Hit for query: 'Do you have ethnic wear?'\n",
            "\n",
            "[CONTEXT]:\n",
            "  Chunk 1 (Rerank Score: -2.0691): Product Name: Ethnicity Gold-Toned Ethnic Embellis...\n",
            "  Chunk 2 (Rerank Score: -2.1206): Product Name: Indo Era Women Classic Off-White Eth...\n",
            "  Chunk 3 (Rerank Score: -2.1978): Product Name: Indo Era Women Bright Orange Ethnic ...\n",
            "\n",
            "[FINAL GENERATED ANSWER (Perplexity Sonar)]:\n",
            "Yes, the Myntra product catalog includes ethnic wear options. Here are some ethnic wear tops available:\n",
            "\n",
            "1. **Ethnicity Gold-Toned Ethnic Embellished Regular Top**  \n",
            "   - Brand: Ethnicity  \n",
            "   - Product ID: 15723640  \n",
            "   - Color: Gold  \n",
            "   - Features: Sleeveless, round neck, embellished with ethnic motifs, cotton blend fabric, regular length, suitable for casual occasions.  \n",
            "   - Price: ₹999  \n",
            "\n",
            "2. **Indo Era Women Classic Off-White Ethnic Motifs Nuovo Sleeves Top**  \n",
            "   - Brand: Indo Era  \n",
            "   - Product ID: 17577456  \n",
            "   - Color: Off White  \n",
            "   - Features: Short puff sleeves, round neck, A-line type, cotton blend, ethnic print/ motifs, ideal for ethnic occasions/brunch.  \n",
            "   - Price: ₹2799  \n",
            "\n",
            "3. **Indo Era Women Bright Orange Ethnic Fusion Top**  \n",
            "   - Brand: Indo Era  \n",
            "   - Product ID: 17577466  \n",
            "   - Color: Orange  \n",
            "   - Features: Short regular sleeves, round neck, A-line type, ethnic printed motifs, cotton blend fabric, suitable for ethnic occasions.  \n",
            "   - Price: ₹2799  \n",
            "\n",
            "These items are categorized as tops with ethnic print and motifs, made from cotton blends, designed for ethnic or casual wear, showing Myntra's availability of ethnic wear products in their catalog.  \n",
            "\n",
            "However, the catalog provided contains only ethnic tops; other categories of ethnic wear like kurtas, sarees, or suits are not listed here.\n",
            "\n",
            "\n",
            "=======================================================\n",
            "TESTING QUERY 2: I'm looking for Kurtas and Trousers\n",
            "=======================================================\n",
            "Cache Hit for query: 'I'm looking for Kurtas and Trousers'\n",
            "\n",
            "[CONTEXT]:\n",
            "  Chunk 1 (Rerank Score: 1.8258): Product Name: HERE&NOW Women Blue Solid Kurta with...\n",
            "  Chunk 2 (Rerank Score: 1.7820): Product Name: Anubhutee Women Green & Blue Printed...\n",
            "  Chunk 3 (Rerank Score: 1.0884): Product Name: Anouk Women Black Printed Kurta with...\n",
            "\n",
            "[FINAL GENERATED ANSWER (Perplexity Sonar)]:\n",
            "Based on the Myntra Product Catalog data provided, here are the available **Kurtas with Trousers** sets:\n",
            "\n",
            "1. **HERE&NOW Women Blue Solid Kurta with Trousers**  \n",
            "   - Brand: HERE&NOW  \n",
            "   - Product ID: 15886988  \n",
            "   - Color: Blue  \n",
            "   - Attributes: Round neck kurta with three-quarter regular sleeves, calf-length straight hemline; made from viscose rayon fabric for both kurta and trousers; trousers with zip closure and partially elasticated waistband; solid pattern; suitable for daily wear; machine washable  \n",
            "   - Price: ₹2399  \n",
            "   - Average Rating: 4.1\n",
            "\n",
            "2. **Anubhutee Women Green & Blue Printed Kurta with Trousers**  \n",
            "   - Brand: Anubhutee  \n",
            "   - Product ID: 13572242  \n",
            "   - Color: Green  \n",
            "   - Attributes: Round neck kurta with three-quarter sleeves, calf-length straight hemline; pure cotton fabric for kurta and viscose rayon for trousers; trousers with drawstring closure and partially elasticated waistband; floral small printed pattern on the kurta, solid trousers; suitable for daily wear; hand wash  \n",
            "   - Price: ₹2989  \n",
            "   - Average Rating: 4.07\n",
            "\n",
            "3. **Anouk Women Black Printed Kurta with Trousers**  \n",
            "   - Brand: Anouk  \n",
            "   - Product ID: 12134668  \n",
            "   - Color: Black  \n",
            "   - Attributes: Round neck kurta with three-quarter sleeves, calf-length straight hemline; pure cotton fabric for both kurta and trousers; trousers are slip-on with partially elasticated waistband; small ethnic motif print on kurta, solid trousers; suitable for daily wear; hand wash  \n",
            "   - Price: ₹2499  \n",
            "   - Average Rating: 4.08\n",
            "\n",
            "These three products represent curated kurta and trouser sets combining style and functionality suitable for everyday use, differing primarily by fabric, print, and price points. If you require kurtas or trousers separately or other variations, that information is not available in the provided product catalog.\n",
            "\n",
            "\n",
            "=======================================================\n",
            "TESTING QUERY 3: Describe the fabric and features of W Women.\n",
            "=======================================================\n",
            "Cache Miss for query: 'Describe the fabric and features of W Women.'. Performing vector search...\n",
            "\n",
            "[CONTEXT]:\n",
            "  Chunk 1 (Rerank Score: 5.0179): Product Name: W Women Navy Wide Leg Solid Palazzos...\n",
            "  Chunk 2 (Rerank Score: 4.8930): Product Name: W Women Off-White & Black Printed Fl...\n",
            "  Chunk 3 (Rerank Score: -1.3889): Product Name: U&F Women Gorgeous Green Solid Tiere...\n",
            "\n",
            "[FINAL GENERATED ANSWER (Perplexity Sonar)]:\n",
            "Based on the Myntra Product Catalog data provided, **W Women** products include:\n",
            "\n",
            "1. **W Women Navy Wide Leg Solid Palazzos**  \n",
            "   - **Fabric:** Acrylic (knitted weave)  \n",
            "   - **Features:** Wide leg fit, regular length, solid pattern, partially elasticated waistband, zip closure, opaque, recommended dry clean care  \n",
            "   - **Color:** Navy Blue  \n",
            "   - **Category:** Palazzos  \n",
            "   - **Product ID:** 2184770\n",
            "\n",
            "2. **W Women Off-White & Black Printed Flared Maxi Skirt**  \n",
            "   - **Fabric:** Pure Cotton (woven)  \n",
            "   - **Features:** Flared type, maxi length, straight hemline, zip closure, has lining, ethnic floral print, opaque, casual occasion, hand wash care  \n",
            "   - **Color:** Off White  \n",
            "   - **Category:** Maxi Skirt  \n",
            "   - **Product ID:** 13646388\n",
            "\n",
            "In summary, **W Women** fabrics range from **acrylic knitted** material in palazzos to **pure cotton woven** fabric in maxi skirts, featuring comfortable, stylish designs with functional closures like zips, varying fits such as wide-leg and flared, and care instructions typically recommending dry cleaning or hand wash. The products offer opaque coverage with either solid or printed ethnic patterns, suitable for western or casual occasions. This suggests the brand focuses on blending comfort with style in its fabric choices and garment features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sat5G__-bXV0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}